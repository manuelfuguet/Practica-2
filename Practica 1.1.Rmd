---
title: "Practica 2"
author: "Manuel, Thommas & Dario"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Datos Elegantes + Análisis de Datos con Web Scrapping 

### Pregunta 1
Queremos programar un programa de tipo web scrapping con el que podamos obtener
una página web, mediante su URL, y poder analizar su contenido HTML con tal de extraer
datos e información específica.
Nuestro programa ha de ser capaz de cumplir con los siguientes pasos:

1. Descargar la página web de la URL indicada, y almacenarlo en un formato de R
apto para ser tratado.
El primer paso para realizar tareas de crawling y scraping es poder descargar los
datos de la web. Para esto usaremos la capacidad de R y de sus librerías (httr y
XML) para descargar webs y almacenarlas en variables que podamos convertir
en un formato fácil de analizar (p.e. de HTML a XML)



# Cargar librerías
library(httr)
library(XML)

# URL de la página web que quieres descargar
url <- "https://www.mediawiki.org/wiki/MediaWiki"

# Descargar la página web
respuesta <- GET(url)

# Verificar si la solicitud fue exitosa
if (status_code(respuesta) == 200) {
  # Extraer el contenido en formato texto
  contenido_html <- content(respuesta, as = "text")
  
  # Convertir el contenido HTML a XML
  contenido_xml <- htmlParse(contenido_html)
  
  # Mostrar estructura del XML
  print(contenido_xml)
} else {
  cat("Error: No se pudo descargar la página web. Código de estado:", status_code(respuesta),"\n")
}
